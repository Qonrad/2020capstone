{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn import metrics\n",
    "\n",
    "trialOrders = {}\n",
    "\n",
    "import os\n",
    "\n",
    "path = './events'\n",
    "\n",
    "def compute_skourascore(subject_performace, idealized_performance):\n",
    "    return scipy.stats.pearsonr(subject_performace, idealized_performance)[0]\n",
    "\n",
    "def compute_auc_score(counterbalanced_angles, length):\n",
    "    score = metrics.auc(np.arange(length * 1.0), counterbalanced_angles) / metrics.auc(np.arange(length * 1.0), np.full((length, 1), 90))\n",
    "    return score\n",
    "\n",
    "def compute_peak_score(counterbalanced_angles):\n",
    "    return np.amax(counterbalanced_angles)\n",
    "\n",
    "def compute_ttp_score(counterbalanced_angles):\n",
    "    return np.argmax(counterbalanced_angles)\n",
    "\n",
    "def find_empty_times(data):\n",
    "    intermissions = data[data['instruction']==\" Push Button\"].index.tolist()\n",
    "    rests = data[data['instruction']==\" Rest\"]\n",
    "    first_scan_index = data[data['instruction']!=\" Rest\"].index.tolist()[0] - 1\n",
    "    first_rest_at_end = data[data['instruction']!=\" Rest\"].index.tolist()[-1] + 1\n",
    "    times = [first_scan_index] + intermissions + [first_rest_at_end]\n",
    "    return times\n",
    "\n",
    "def determine_trialorder(data, times):\n",
    "    trialOrder = []\n",
    "    for trialnum in range(12):\n",
    "        this_trial = data[(times[trialnum] + 1):times[trialnum + 1]][data['feedback']==\"On\"]\n",
    "        trialOrder += [this_trial['left_text'].tolist()[0][1:] + \"-\" + this_trial['right_text'].tolist()[0][1:], this_trial['instruction'].tolist()[0][1:]]\n",
    "    return trialOrder\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.tsv' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "means_template = {'ID':[], 'down': [], 'up': [], 'both': []}\n",
    "\n",
    "series_template = {'ID':[]}\n",
    "for i in range(1, 13):\n",
    "    series_template[str(i)] = []\n",
    "\n",
    "downseries_template = {'ID':[]}\n",
    "for i in range(1, 7):\n",
    "    downseries_template[str(i)] = []\n",
    "    \n",
    "upseries_template = {'ID':[]}\n",
    "for i in range(1, 7):\n",
    "    upseries_template[str(i)] = []\n",
    "\n",
    "skouradict = {'means':copy.deepcopy(means_template), 'series':copy.deepcopy(series_template), 'downseries':copy.deepcopy(downseries_template), 'upseries': copy.deepcopy(upseries_template)}\n",
    "aucdict = {'means':copy.deepcopy(means_template), 'series':copy.deepcopy(series_template), 'downseries':copy.deepcopy(downseries_template), 'upseries': copy.deepcopy(upseries_template)}\n",
    "peakdict = {'means':copy.deepcopy(means_template), 'series':copy.deepcopy(series_template), 'downseries':copy.deepcopy(downseries_template), 'upseries': copy.deepcopy(upseries_template)}\n",
    "ttpdict = {'means':copy.deepcopy(means_template), 'series':copy.deepcopy(series_template), 'downseries':copy.deepcopy(downseries_template), 'upseries': copy.deepcopy(upseries_template)}\n",
    "\n",
    "for i in range(len(files)):\n",
    "    #parsing filename to find NKI subject ID\n",
    "    subpos = files[i].find('sub-A')\n",
    "    subjID = files[i][(subpos + 4):(subpos + 13)]\n",
    "    #reading events.tsv file as \"data\"\n",
    "    data = pd.read_csv(files[i], sep=\"\\t\")\n",
    "    times = find_empty_times(data)\n",
    "    trialOrder = determine_trialorder(data, times)\n",
    "    \n",
    "    skouradict['series']['ID'] += [subjID]\n",
    "    skouradict['upseries']['ID'] += [subjID]\n",
    "    skouradict['downseries']['ID'] += [subjID]\n",
    "    \n",
    "    aucdict['series']['ID'] += [subjID]\n",
    "    aucdict['upseries']['ID'] += [subjID]\n",
    "    aucdict['downseries']['ID'] += [subjID]\n",
    "    \n",
    "    peakdict['series']['ID'] += [subjID]\n",
    "    peakdict['upseries']['ID'] += [subjID]\n",
    "    peakdict['downseries']['ID'] += [subjID]\n",
    "    \n",
    "    ttpdict['series']['ID'] += [subjID]\n",
    "    ttpdict['upseries']['ID'] += [subjID]\n",
    "    ttpdict['downseries']['ID'] += [subjID]\n",
    "    \n",
    "    series_position = 1\n",
    "    downseries_position = 1\n",
    "    upseries_position = 1\n",
    "    \n",
    "    for trialnum in range(12):\n",
    "        #this_trial is the data just from the trial of trialnum\n",
    "        #this_trial is set to the FIRST 15 TRs (first 30 seconds) of each trial!\n",
    "        this_trial = data[(times[trialnum] + 1):times[trialnum + 1]]#[0:16]\n",
    "        length = len(this_trial.needle_position.values)\n",
    "        instruction = trialOrder[(trialnum * 2) + 1]\n",
    "        polarity = trialOrder[(trialnum * 2)]\n",
    "        if instruction == \"Focus\":\n",
    "            if polarity == 'Focused-Wandering':\n",
    "                idealized = np.linspace(90, 90 + (length - 1), num=length)\n",
    "                auc_balanced = (this_trial.needle_position.values - 90)\n",
    "            elif polarity == 'Wandering-Focused':\n",
    "                idealized = np.linspace(90, 90 - (length - 1), num=length)\n",
    "                auc_balanced = (this_trial.needle_position.values - 90) * -1\n",
    "            \n",
    "            #calculating scores\n",
    "            auc = compute_auc_score(auc_balanced, length)\n",
    "            skourascore = compute_skourascore(this_trial.needle_position.values, idealized)\n",
    "            peak = compute_peak_score(auc_balanced)\n",
    "            ttp = compute_ttp_score(auc_balanced)\n",
    "            \n",
    "            #storing scores in memory\n",
    "            skouradict['downseries'][str(downseries_position)] += [skourascore]\n",
    "            aucdict['downseries'][str(downseries_position)] += [auc]\n",
    "            peakdict['downseries'][str(downseries_position)] += [peak]\n",
    "            ttpdict['downseries'][str(downseries_position)] += [ttp]\n",
    "            \n",
    "            downseries_position += 1\n",
    "        elif instruction == \"Wander\":\n",
    "            if polarity == 'Focused-Wandering':\n",
    "                idealized = np.linspace(90, 90 - (length - 1), num=length)\n",
    "                auc_balanced = (this_trial.needle_position.values - 90) * -1\n",
    "            elif polarity == 'Wandering-Focused':\n",
    "                idealized = np.linspace(90, 90 + (length - 1), num=length)\n",
    "                auc_balanced = (this_trial.needle_position.values - 90)\n",
    "            \n",
    "            #calculating scores\n",
    "            auc = compute_auc_score(auc_balanced, length)\n",
    "            skourascore = compute_skourascore(this_trial.needle_position.values, idealized)\n",
    "            peak = compute_peak_score(auc_balanced)\n",
    "            ttp = compute_ttp_score(auc_balanced)\n",
    "            \n",
    "            #storing scores in memory\n",
    "            skouradict['upseries'][str(upseries_position)] += [skourascore]\n",
    "            aucdict['upseries'][str(upseries_position)] += [auc]\n",
    "            peakdict['upseries'][str(upseries_position)] += [peak]\n",
    "            ttpdict['upseries'][str(upseries_position)] += [ttp]\n",
    "            \n",
    "            upseries_position += 1\n",
    "        else:\n",
    "            print(\"something is horribly wrong\")\n",
    "        skouradict['series'][str(series_position)] += [skourascore]\n",
    "        aucdict['series'][str(series_position)] += [auc]\n",
    "        peakdict['series'][str(series_position)] += [peak]\n",
    "        ttpdict['series'][str(series_position)] += [ttp]\n",
    "        \n",
    "        series_position += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert series dicts into dataframes\n",
    "#first skourascores\n",
    "skouraseries = pd.DataFrame(skouradict['series'])\n",
    "skouradownseries = pd.DataFrame(skouradict['downseries'])\n",
    "skouraupseries = pd.DataFrame(skouradict['upseries'])\n",
    "#now AUC scores\n",
    "aucseries = pd.DataFrame(aucdict['series'])\n",
    "aucdownseries = pd.DataFrame(aucdict['downseries'])\n",
    "aucupseries = pd.DataFrame(aucdict['upseries'])\n",
    "#now peak scores\n",
    "ttpseries = pd.DataFrame(ttpdict['series'])\n",
    "ttpdownseries = pd.DataFrame(ttpdict['downseries'])\n",
    "ttpupseries = pd.DataFrame(ttpdict['upseries'])\n",
    "#now TTP scores\n",
    "peakseries = pd.DataFrame(peakdict['series'])\n",
    "peakdownseries = pd.DataFrame(peakdict['downseries'])\n",
    "peakupseries = pd.DataFrame(peakdict['upseries'])\n",
    "\n",
    "#now sort them by IDs\n",
    "skouraseries.sort_values(by=['ID'])\n",
    "skouradownseries.sort_values(by=['ID'])\n",
    "skouraupseries.sort_values(by=['ID'])\n",
    "aucseries.sort_values(by=['ID'])\n",
    "aucdownseries.sort_values(by=['ID'])\n",
    "aucupseries.sort_values(by=['ID'])\n",
    "ttpseries.sort_values(by=['ID'])\n",
    "ttpdownseries.sort_values(by=['ID'])\n",
    "ttpupseries.sort_values(by=['ID'])\n",
    "peakseries.sort_values(by=['ID'])\n",
    "peakdownseries.sort_values(by=['ID'])\n",
    "peakupseries.sort_values(by=['ID'])\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating skouras-style \"learning\" score. \"learning\" in this context is measured as the average of trials 4-6 minus the average of trials 1-3. This \"learning\" measurement is independent of score-type, and can be calculated for each one.\n",
    "\n",
    "It also calculates the 6-1 learning measure.\n",
    "\n",
    "I define a function for calculating \"learning\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function assumes a trial-series of length 6 (either up or down regulation, but not both)\n",
    "def add_learning_measures(series):\n",
    "    series['first_avg'] = series[['1', '2','3']].mean(axis=1)\n",
    "    series['second_avg'] = series[['4', '5','6']].mean(axis=1)\n",
    "    series['skouras_learning'] = series['second_avg'] - series['first_avg']\n",
    "    series['six_minus_one'] = series['6'] - series['1']\n",
    "    series['difference_between_measures'] = series['six_minus_one'] - series['skouras_learning']\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function for plotting learning curves and histograms of arbitrary # of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def learningcurve(seriesdata, length, scoretype):\n",
    "    x = []\n",
    "    for i in range(length):\n",
    "        x += [i + 1]\n",
    "\n",
    "    series = pd.DataFrame(seriesdata)\n",
    "    series = series.sort_values(by=['ID'])\n",
    "    series = series.to_numpy()\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    diffs = []\n",
    "    for j in range(len(series)):\n",
    "        x=np.asarray(x).astype(np.float)\n",
    "        ax[0].scatter(x, series[j][1:], color='b', alpha=0.1)\n",
    "        diffs += [series[j][6] - series[j][1]]\n",
    "        y = series[j][1:].astype(np.float)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax[0].plot(x,p(x),\"r\", alpha=0.2)\n",
    "    ax[1].hist(diffs, 4)\n",
    "    # set ticks and tick labels\n",
    "    ax[0].set_xlim((1, length))\n",
    "    ax[0].set_xticks(x)\n",
    "    ax[0].set_xticklabels(x)\n",
    "\n",
    "    plt.xlabel('Trial Position (not the actual trial number)')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(scoretype + ' learning curves')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def series_histogram(seriesdata, scoretype, length, n_bins):\n",
    "    series = pd.DataFrame(seriesdata)\n",
    "    series = series.sort_values(by=['ID'])\n",
    "\n",
    "    fig, axs = plt.subplots(length, 1, sharey=True, sharex=True)\n",
    "    for trialPos in range(length):\n",
    "        axs[trialPos].hist(series[str(trialPos + 1)].to_list(), bins=n_bins)\n",
    "        axs[trialPos].set_title(scoretype + ' Trial ' + str(trialPos + 1))\n",
    "    plt.xlabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in age and clinical status csv file made in pmetrics.ipynb.\n",
    "\n",
    "Going to test for interesting correlations with them and the other data.\n",
    "\n",
    "From skouras:\n",
    "    In the control group, age (M = 30.71 years; SD = 7.48; nb = 62) correlated negatively with overall DMN NF performance score (M = 0.195, SD = 0.312) with a moderate association that explained 17% of the variance, r(62)=-0.412, R2 = 0.17, P = 0.0009; Fig. 3B.\n",
    "    \n",
    "My output:\n",
    "    In the control group, age ( M = 32.05501195912154  years; SD = 7.8142617590016386 n = 63 ) correlated negatively with overall DMN NF performance score ( M = 0.19537175723329936 SD = 0.2955934924510536 ) with an association that explained 17.79582649049908 % of the variance, r(63) = -0.4218509984639017 R2 = 0.1779582649049908 P = 0.0005741932845391171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07629058476960415\n",
      "0.0009999999999998899\n",
      "temporarily changed it to looking at whole trials\n",
      "Skouras's 'overall performance' is the average score from the last 6 trials.\n",
      "[27.9260274  38.44931507 25.40547945 36.83013699 25.72054795 34.96438356\n",
      " 22.51780822 28.76986301 35.79178082 25.92328767 36.56712329 26.47671233\n",
      " 38.56712329 30.34794521 29.64109589 32.95616438 39.70958904 39.11506849\n",
      " 29.78630137 36.46027397 25.6        36.51232877 30.77808219 42.6109589\n",
      " 38.68219178 22.40273973 21.67945205 23.50410959 27.95616438 37.96712329\n",
      " 24.81917808 42.19452055 39.97534247 21.90410959 42.63013699 34.78630137\n",
      " 44.53424658 27.79178082 22.63561644 31.0630137  23.02191781 23.89315068\n",
      " 26.49315068 27.67671233 24.66575342 40.22739726 37.09315068 23.01917808\n",
      " 23.13150685 37.55342466 46.02739726 29.7369863  42.8        43.75342466\n",
      " 47.34520548 44.16438356 48.06849315 22.7890411  23.22191781 33.64383562\n",
      " 22.90958904 22.82739726 23.44931507]\n",
      "[ 0.04722563  0.14979651  0.08793223  0.03658911  0.08724884  0.01573259\n",
      "  0.02921578  0.08914854  0.06182824  0.1042878   0.09632773  0.03457398\n",
      "  0.45897504 -0.20599853  0.71878742  0.14995089  0.22249583  0.05826388\n",
      "  0.0611219   0.13538116  0.16304171  0.09478895  0.32067203  0.06663242\n",
      "  0.0580711   0.50158511  0.32317577  0.24257457  0.16259909 -0.00449856\n",
      "  0.31412586  0.01164819  0.13970444  0.16973363  0.02799954  0.04167267\n",
      " -0.02974954  0.24807212  0.32359672  0.28933183  0.06190153  0.06544951\n",
      "  0.24444406  0.0504871  -0.06590597  0.14865443  0.27635681  0.24223787\n",
      " -0.03289766  0.21837439 -0.09427968 -0.07069358  0.13855328 -0.15667274\n",
      "  0.10836113  0.1499075   0.12818767  0.0117404   0.2603919   0.0048692\n",
      "  0.08114932  0.14350148 -0.02467304]\n",
      "In the control group, age ( M = 32.05501195912154  years; SD = 7.8142617590016386 n = 63 ) correlated negatively with overall DMN NF performance score ( M = 0.12370011281879006 SD = 0.1517895543765369 ) with an association that explained 3.807668806010958 % of the variance, r(63) = -0.19513248847926268 R2 = 0.03807668806010958 P = 0.12538060111628727\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from scipy import stats\n",
    "\n",
    "diags_ages = pd.read_csv('./diags_ages.csv')\n",
    "\n",
    "ages = diags_ages.dropna(subset=['AGE']).AGE.values\n",
    "ksstat, pval = lilliefors(ages, pvalmethod='table')\n",
    "print(ksstat)\n",
    "print(pval)\n",
    "\n",
    "trials = skouraseries.loc[: , \"6\":\"12\"]\n",
    "#display(trials)\n",
    "skouraseries['overall_performance'] = trials.mean(axis=1)\n",
    "#display(skouraseries)\n",
    "overall_only = skouraseries[['ID', 'overall_performance']]\n",
    "\n",
    "ages_perf = pd.merge(overall_only, diags_ages, how='inner', on='ID').sort_values(by=['ID']).reset_index(drop=True)\n",
    "ages_perf = ages_perf.drop_duplicates(subset='ID').reset_index(drop=True)\n",
    "\n",
    "ages_perf_control = ages_perf[ages_perf['DIAG_01#CODE'] == 'V71.09'].sort_values(by=['ID']).reset_index(drop=True)\n",
    "ages_perf_path = ages_perf[ages_perf['DIAG_01#CODE'] != 'V71.09'].sort_values(by=['ID']).reset_index(drop=True)\n",
    "\n",
    "#display(ages_perf_control)\n",
    "print(\"temporarily changed it to looking at whole trials\")\n",
    "print(\"Skouras's 'overall performance' is the average score from the last 6 trials.\")\n",
    "\n",
    "control_ages = ages_perf_control.AGE_04.values\n",
    "control_performance = ages_perf_control.overall_performance.values\n",
    "print(control_ages)\n",
    "print(control_performance)\n",
    "rho, p = stats.spearmanr(control_ages, control_performance)\n",
    "print(\"In the control group, age ( M =\", control_ages.mean(), \" years; SD =\", control_ages.std(), \"n =\", len(control_ages), \") correlated negatively with overall DMN NF performance score ( M =\", control_performance.mean(), \"SD =\", control_performance.std(), \") with an association that explained\", (rho ** 2) * 100,\"% of the variance, r(63) =\", rho,\"R2 =\", rho ** 2, \"P =\", p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def learning_hist(series, title, dosample=False):\n",
    "    if dosample:\n",
    "        print(title, \"score\")\n",
    "        print(\"Average difference between measures =\", series['difference_between_measures'].mean(axis=0))\n",
    "        print('skouras_learning measure has a variance of', np.var(series[['skouras_learning']].values))\n",
    "        print('6-1 measure has a variance of', np.var(series[['six_minus_one']].values))\n",
    "        print(\"Here is a random sample of 10 subjects.\")\n",
    "        print(series[['skouras_learning','six_minus_one', 'difference_between_measures']].sample(10))\n",
    "    plt.figure()\n",
    "    x = series[['skouras_learning']].values\n",
    "    y = series[['six_minus_one']].values\n",
    "    sns.distplot(x, kde=True, rug=True, label=\"avg(4,5,6)-avg(1,2,3)\")\n",
    "    sns.distplot(y, kde=True, rug=True, label=\"6 - 1\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "aucdownserieslearning = add_learning_measures(aucdownseries)\n",
    "skouradownserieslearning = add_learning_measures(skouradownseries)\n",
    "ttpdownserieslearning = add_learning_measures(ttpdownseries)\n",
    "peakdownserieslearning = add_learning_measures(peakdownseries)\n",
    "\n",
    "\n",
    "learning_hist(aucdownserieslearning, \"AUC\", dosample=True)\n",
    "learning_hist(skouradownserieslearning, \"Skouras-Score\", dosample=True)\n",
    "learning_hist(ttpdownserieslearning, \"Time-to-peak\", dosample=True)\n",
    "learning_hist(peakdownserieslearning, \"Peak\", dosample=True)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 250em; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
