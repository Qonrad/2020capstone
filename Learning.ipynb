{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIAG_01#CODE</th>\n",
       "      <th>resting_asleep</th>\n",
       "      <th>feedback_asleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>96.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>96.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIAG_01#CODE resting_asleep feedback_asleep\n",
       "0          71.09            1.0             0.0\n",
       "1           0.29            1.0             1.0\n",
       "2          71.09            1.0             0.0\n",
       "3          96.26            0.0             0.0\n",
       "4            5.0            0.0             0.0\n",
       "..           ...            ...             ...\n",
       "132          5.0            1.0             0.0\n",
       "133          3.9            0.0             0.0\n",
       "134         0.29            0.0             0.0\n",
       "135        96.36            0.0             0.0\n",
       "136        96.26            1.0             0.0\n",
       "\n",
       "[137 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "Spearman r = -0.2044806672421322 R2 =  0.0418123432757876 p =  0.016537248499776006\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    6.8s finished\n",
      "/home/rad/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Best parameters set found on development set:\n",
      "\n",
      "{'reduce_dim__k': 137, 'svr__C': 0.1, 'svr__kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.261 (+/-0.434) for {'reduce_dim__k': 30, 'svr__C': 0.1, 'svr__kernel': 'linear'}\n",
      "-0.081 (+/-0.315) for {'reduce_dim__k': 30, 'svr__C': 0.1, 'svr__kernel': 'rbf'}\n",
      "-0.081 (+/-0.359) for {'reduce_dim__k': 30, 'svr__C': 0.001, 'svr__kernel': 'linear'}\n",
      "-0.135 (+/-0.279) for {'reduce_dim__k': 30, 'svr__C': 0.001, 'svr__kernel': 'rbf'}\n",
      "-0.111 (+/-0.295) for {'reduce_dim__k': 30, 'svr__C': 0.0001, 'svr__kernel': 'linear'}\n",
      "-0.139 (+/-0.284) for {'reduce_dim__k': 30, 'svr__C': 0.0001, 'svr__kernel': 'rbf'}\n",
      "-149.398 (+/-595.140) for {'reduce_dim__k': 137, 'svr__C': 0.1, 'svr__kernel': 'linear'}\n",
      "-0.035 (+/-0.270) for {'reduce_dim__k': 137, 'svr__C': 0.1, 'svr__kernel': 'rbf'}\n",
      "-0.670 (+/-2.899) for {'reduce_dim__k': 137, 'svr__C': 0.001, 'svr__kernel': 'linear'}\n",
      "-0.136 (+/-0.283) for {'reduce_dim__k': 137, 'svr__C': 0.001, 'svr__kernel': 'rbf'}\n",
      "-0.071 (+/-0.262) for {'reduce_dim__k': 137, 'svr__C': 0.0001, 'svr__kernel': 'linear'}\n",
      "-0.139 (+/-0.284) for {'reduce_dim__k': 137, 'svr__C': 0.0001, 'svr__kernel': 'rbf'}\n",
      "-40.966 (+/-79.906) for {'reduce_dim__k': 'all', 'svr__C': 0.1, 'svr__kernel': 'linear'}\n",
      "-0.064 (+/-0.245) for {'reduce_dim__k': 'all', 'svr__C': 0.1, 'svr__kernel': 'rbf'}\n",
      "-20.152 (+/-54.845) for {'reduce_dim__k': 'all', 'svr__C': 0.001, 'svr__kernel': 'linear'}\n",
      "-0.137 (+/-0.281) for {'reduce_dim__k': 'all', 'svr__C': 0.001, 'svr__kernel': 'rbf'}\n",
      "-0.153 (+/-0.230) for {'reduce_dim__k': 'all', 'svr__C': 0.0001, 'svr__kernel': 'linear'}\n",
      "-0.140 (+/-0.284) for {'reduce_dim__k': 'all', 'svr__C': 0.0001, 'svr__kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on 116 subjects.\n",
      "The scores are computed on 21 subjects.\n",
      "\n",
      "-0.5210252459654037\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:   26.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "DEPENDENT_VARIABLE = 'avg2ndhalf'\n",
    "USE_GRANGER = False\n",
    "USE_NUMERICAL_PSYCHOMETRICS = True\n",
    "USE_CATEGORICAL_PSYCHOMETRICS = True\n",
    "\n",
    "# Read DF containing dependent variable\n",
    "ydf = pd.read_csv(\"./dependent.csv\")\n",
    "ydf.set_index('ID', inplace=True)\n",
    "ydf = ydf[[DEPENDENT_VARIABLE]]\n",
    "\n",
    "\n",
    "\n",
    "if USE_NUMERICAL_PSYCHOMETRICS:\n",
    "    numerical_psychometrics = pd.read_csv('./imputed_numerical_psychometrics.csv')\n",
    "    ydf = pd.merge(ydf, numerical_psychometrics, how='inner', on='ID')\n",
    "#     ydf.set_index('ID', inplace=True)\n",
    "\n",
    "if USE_CATEGORICAL_PSYCHOMETRICS:\n",
    "    categorical_psychometrics = pd.read_csv('./unimputed_categorical_psychometrics.csv')\n",
    "    categorical_psychometrics['DIAG_01#CODE'] = categorical_psychometrics['DIAG_01#CODE'].astype(str)\n",
    "    categorical_psychometrics['resting_asleep'] = categorical_psychometrics['resting_asleep'].astype(str)\n",
    "    categorical_psychometrics['feedback_asleep'] = categorical_psychometrics['feedback_asleep'].astype(str)\n",
    "    ydf = pd.merge(ydf, categorical_psychometrics, how='inner', on='ID')\n",
    "    display(ydf[['DIAG_01#CODE', 'resting_asleep', 'feedback_asleep']])\n",
    "# display(ydf)\n",
    "\n",
    "print(\"Sanity Check\")\n",
    "r, p = stats.spearmanr(ydf[DEPENDENT_VARIABLE].values, ydf['bids_age'].values)\n",
    "print(\"Spearman r =\", r, \"R2 = \", r ** 2, \"p = \", p)\n",
    "\n",
    "y = ydf[DEPENDENT_VARIABLE].values\n",
    "ydf.drop(columns=[DEPENDENT_VARIABLE, 'ID'], inplace=True)\n",
    "X = ydf\n",
    "\n",
    "# display(X)\n",
    "\n",
    "# causality_df.loc[:, causality_df.columns != 'ID'].to_numpy()\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = numerical_psychometrics.drop(columns=['ID']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['DIAG_01#CODE', 'resting_asleep', 'feedback_asleep']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# display(X)\n",
    "\n",
    "# raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset in two parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "feats = len(X.columns)\n",
    "subs = len(y)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # the reduce_dim stage is populated by the param_grid\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('reduce_dim', SelectKBest(mutual_info_regression)),\n",
    "    ('svr', SVR(verbose=10))\n",
    "])\n",
    "\n",
    "#setting feature_selection params appropriately\n",
    "N_FEATURES_OPTIONS = [30, subs, \"all\"]\n",
    "\n",
    "C_OPTIONS = [0.0001, 0.001, 0.1]\n",
    "C_OPTIONS.reverse()\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'svr__kernel': ['linear', 'rbf'],\n",
    "        'svr__C': C_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, iid=False, verbose=10)\n",
    "\n",
    "# display(X_train)\n",
    "# raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on\", len(y_train), \"subjects.\")\n",
    "print(\"The scores are computed on\", len(y_test), \"subjects.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid.predict(X_test)\n",
    "print(r2_score(y_true, y_pred))\n",
    "\n",
    "#---------------------------------------------------------------------------------------- \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # the reduce_dim stage is populated by the param_grid\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('reduce_dim', SelectKBest(mutual_info_regression)),\n",
    "    ('kr', KernelRidge())\n",
    "])\n",
    "\n",
    "#setting feature_selection params appropriately\n",
    "N_FEATURES_OPTIONS = [30, subs, \"all\"]\n",
    "\n",
    "A_OPTIONS = [0.0001, 0.001, 0.1]\n",
    "G_OPTIONS = np.logspace(-2, 2, 5)\n",
    "C_OPTIONS.reverse()\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'kr__kernel': ['linear', 'rbf'],\n",
    "        'kr__alpha': A_OPTIONS,\n",
    "        'kr__gamma': G_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on\", len(y_train), \"subjects.\")\n",
    "print(\"The scores are computed on\", len(y_test), \"subjects.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid.predict(X_test)\n",
    "print(r2_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
