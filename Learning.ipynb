{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg2ndhalf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00028185</th>\n",
       "      <td>-0.072119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00032875</th>\n",
       "      <td>-0.069486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00033747</th>\n",
       "      <td>0.311871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00034854</th>\n",
       "      <td>0.354473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00035072</th>\n",
       "      <td>0.752141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00066827</th>\n",
       "      <td>0.181018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00066926</th>\n",
       "      <td>0.410703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00072203</th>\n",
       "      <td>0.168672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00073600</th>\n",
       "      <td>0.712602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00073677</th>\n",
       "      <td>0.017829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           avg2ndhalf\n",
       "ID                   \n",
       "A00028185   -0.072119\n",
       "A00032875   -0.069486\n",
       "A00033747    0.311871\n",
       "A00034854    0.354473\n",
       "A00035072    0.752141\n",
       "...               ...\n",
       "A00066827    0.181018\n",
       "A00066926    0.410703\n",
       "A00072203    0.168672\n",
       "A00073600    0.712602\n",
       "A00073677    0.017829\n",
       "\n",
       "[138 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIAG_01#CODE</th>\n",
       "      <th>resting_asleep</th>\n",
       "      <th>feedback_asleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>96.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>96.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIAG_01#CODE resting_asleep feedback_asleep\n",
       "0          71.09            1.0             0.0\n",
       "1           0.29            1.0             1.0\n",
       "2          71.09            1.0             0.0\n",
       "3          96.26            0.0             0.0\n",
       "4            5.0            0.0             0.0\n",
       "..           ...            ...             ...\n",
       "132          5.0            1.0             0.0\n",
       "133          3.9            0.0             0.0\n",
       "134         0.29            0.0             0.0\n",
       "135        96.36            0.0             0.0\n",
       "136        96.26            1.0             0.0\n",
       "\n",
       "[137 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check\n",
      "Spearman r = -0.2044806672421322 R2 =  0.0418123432757876 p =  0.016537248499776006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "DEPENDENT_VARIABLE = 'avg2ndhalf'\n",
    "USE_GRANGER = False\n",
    "USE_NUMERICAL_PSYCHOMETRICS = True\n",
    "USE_CATEGORICAL_PSYCHOMETRICS = True\n",
    "\n",
    "# Read DF containing dependent variable\n",
    "ydf = pd.read_csv(\"./dependent.csv\")\n",
    "ydf.set_index('ID', inplace=True)\n",
    "ydf = ydf[[DEPENDENT_VARIABLE]]\n",
    "\n",
    "if USE_NUMERICAL_PSYCHOMETRICS:\n",
    "    numerical_psychometrics = pd.read_csv('./imputed_numerical_psychometrics.csv')\n",
    "    ydf = pd.merge(ydf, numerical_psychometrics, how='left', on='ID')\n",
    "\n",
    "if USE_CATEGORICAL_PSYCHOMETRICS:\n",
    "    categorical_psychometrics = pd.read_csv('./unimputed_categorical_psychometrics.csv')\n",
    "    categorical_psychometrics['DIAG_01#CODE'] = categorical_psychometrics['DIAG_01#CODE'].astype(str)\n",
    "    categorical_psychometrics['resting_asleep'] = categorical_psychometrics['resting_asleep'].astype(str)\n",
    "    categorical_psychometrics['feedback_asleep'] = categorical_psychometrics['feedback_asleep'].astype(str)\n",
    "    ydf = pd.merge(ydf, categorical_psychometrics, how='left', on='ID')\n",
    "    display(ydf[['DIAG_01#CODE', 'resting_asleep', 'feedback_asleep']])\n",
    "# display(ydf)\n",
    "\n",
    "print(\"Sanity Check\")\n",
    "r, p = stats.spearmanr(ydf[DEPENDENT_VARIABLE].values, ydf['bids_age'].values)\n",
    "print(\"Spearman r =\", r, \"R2 = \", r ** 2, \"p = \", p)\n",
    "\n",
    "y = ydf[DEPENDENT_VARIABLE].values\n",
    "ydf.drop(columns=[DEPENDENT_VARIABLE, 'ID'], inplace=True)\n",
    "X = ydf\n",
    "\n",
    "# display(X)\n",
    "\n",
    "# causality_df.loc[:, causality_df.columns != 'ID'].to_numpy()\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = numerical_psychometrics.drop(columns=['ID']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['DIAG_01#CODE', 'resting_asleep', 'feedback_asleep']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# display(X)\n",
    "\n",
    "# raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset in two parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "feats = len(X.columns)\n",
    "subs = len(y)\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     # the reduce_dim stage is populated by the param_grid\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('reduce_dim', SelectKBest(mutual_info_regression)),\n",
    "#     ('svr', SVR(verbose=10))\n",
    "# ])\n",
    "\n",
    "# #setting feature_selection params appropriately\n",
    "# N_FEATURES_OPTIONS = [30, subs, \"all\"]\n",
    "\n",
    "# C_OPTIONS = [0.0001, 0.001, 0.1]\n",
    "# C_OPTIONS.reverse()\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "#         'svr__kernel': ['linear', 'rbf'],\n",
    "#         'svr__C': C_OPTIONS\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, iid=False, verbose=10)\n",
    "\n",
    "# # display(X_train)\n",
    "# # raise SystemExit(\"Stop right there!\")\n",
    "\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters set found on development set:\")\n",
    "# print()\n",
    "# print(grid.best_params_)\n",
    "# print()\n",
    "# print(\"Grid scores on development set:\")\n",
    "# print()\n",
    "# means = grid.cv_results_['mean_test_score']\n",
    "# stds = grid.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#           % (mean, std * 2, params))\n",
    "# print()\n",
    "\n",
    "# print(\"Detailed classification report:\")\n",
    "# print()\n",
    "# print(\"The model is trained on\", len(y_train), \"subjects.\")\n",
    "# print(\"The scores are computed on\", len(y_test), \"subjects.\")\n",
    "# print()\n",
    "# y_true, y_pred = y_test, grid.predict(X_test)\n",
    "# print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    3.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    5.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    5.6s finished\n",
      "/home/rad/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 100, 'reduce_dim__k': 30}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.218 (+/-0.115) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 100, 'reduce_dim__k': 30}\n",
      "-0.308 (+/-0.296) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 100, 'reduce_dim__k': 137}\n",
      "-0.237 (+/-0.431) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 100, 'reduce_dim__k': 'all'}\n",
      "-0.439 (+/-0.499) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 500, 'reduce_dim__k': 30}\n",
      "-0.461 (+/-0.231) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 500, 'reduce_dim__k': 137}\n",
      "-0.329 (+/-0.483) for {'gbr__learning_rate': 0.01, 'gbr__loss': 'ls', 'gbr__max_depth': 4, 'gbr__min_samples_split': 2, 'gbr__n_estimators': 500, 'reduce_dim__k': 'all'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on 116 subjects.\n",
      "The scores are computed on 21 subjects.\n",
      "\n",
      "-0.03070824321212373\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # the reduce_dim stage is populated by the param_grid\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('reduce_dim', SelectKBest(mutual_info_regression)),\n",
    "    ('gbr', ensemble.GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "#setting feature_selection params appropriately\n",
    "N_FEATURES_OPTIONS = [30, subs, \"all\"]\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'gbr__n_estimators': [100, 500],\n",
    "        'gbr__max_depth': [4],\n",
    "        'gbr__min_samples_split': [2],\n",
    "        'gbr__learning_rate': [0.01],\n",
    "        'gbr__loss': ['ls']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, iid=False, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on\", len(y_train), \"subjects.\")\n",
    "print(\"The scores are computed on\", len(y_test), \"subjects.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid.predict(X_test)\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------- \n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     # the reduce_dim stage is populated by the param_grid\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('reduce_dim', SelectKBest(mutual_info_regression)),\n",
    "#     ('kr', KernelRidge())\n",
    "# ])\n",
    "\n",
    "# #setting feature_selection params appropriately\n",
    "# N_FEATURES_OPTIONS = [30, subs, \"all\"]\n",
    "\n",
    "# A_OPTIONS = [0.0001, 0.001, 0.1]\n",
    "# G_OPTIONS = np.logspace(-2, 2, 5)\n",
    "# C_OPTIONS.reverse()\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "#         'kr__kernel': ['linear', 'rbf'],\n",
    "#         'kr__alpha': A_OPTIONS,\n",
    "#         'kr__gamma': G_OPTIONS\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, iid=False, verbose=10)\n",
    "\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters set found on development set:\")\n",
    "# print()\n",
    "# print(grid.best_params_)\n",
    "# print()\n",
    "# print(\"Grid scores on development set:\")\n",
    "# print()\n",
    "# means = grid.cv_results_['mean_test_score']\n",
    "# stds = grid.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#           % (mean, std * 2, params))\n",
    "# print()\n",
    "\n",
    "# print(\"Detailed classification report:\")\n",
    "# print()\n",
    "# print(\"The model is trained on\", len(y_train), \"subjects.\")\n",
    "# print(\"The scores are computed on\", len(y_test), \"subjects.\")\n",
    "# print()\n",
    "# y_true, y_pred = y_test, grid.predict(X_test)\n",
    "# print(r2_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
