{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>conn_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00028185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00032875</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00033747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00034854</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00035072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>A00066827</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>A00066926</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>A00072203</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>A00073600</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>A00073677</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  conn_ID\n",
       "0    A00028185        1\n",
       "1    A00032875        3\n",
       "2    A00033747        4\n",
       "3    A00034854        5\n",
       "4    A00035072        6\n",
       "..         ...      ...\n",
       "133  A00066827      151\n",
       "134  A00066926      152\n",
       "135  A00072203      153\n",
       "136  A00073600      154\n",
       "137  A00073677      155\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "all_bids_ids = pd.read_csv(\"nfb_subset_SUBJECT_IDS.csv\")\n",
    "all_bids_ids['ID'] = all_bids_ids['ID'].str[4:]\n",
    "all_bids_ids['conn_ID'] = all_bids_ids.index + 1\n",
    "\n",
    "all_score_ids = pd.read_csv(\"events_IDs.csv\")\n",
    "\n",
    "bids_subset_ids = pd.merge(all_score_ids, all_bids_ids, how='inner', on='ID').sort_values(by=['ID']).reset_index(drop=True)\n",
    "display(bids_subset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an error occured that prevented causality calculation for ./timeseries_CSVs/ROI_Subject080_Session001.csv\n",
      "an error occured that prevented causality calculation for ./timeseries_CSVs/ROI_Subject102_Session001.csv\n",
      "an error occured that prevented causality calculation for ./timeseries_CSVs/ROI_Subject111_Session001.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(135, 435)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    ".. gc-fmri\n",
    "\n",
    "================================\n",
    "Granger 'causality' of fMRI data\n",
    "================================\n",
    "\n",
    "Granger 'causality' analysis provides an asymmetric measure of the coupling\n",
    "between two time-series. When discussing this analysis method, we will put the\n",
    "word 'causality' in single quotes, as we believe that use of this word outside\n",
    "of quotes should be reserved for particular circumstances, often not fulfilled\n",
    "in the analysis of simultaneously recorder neuroscientific time-series (see\n",
    "[Pearl2009]_ for an extensive discussion of this distinction).\n",
    "\n",
    "The central idea behind this analysis is that time-series can be described in\n",
    "terms of a time-delayed auto-regressive model of the form:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   x_t = \\sum_{i=1}^{n}a_i x_{t-i} + \\epsilon_t\n",
    "\n",
    "Here, the past behaviour of a single time-series is used in order to predict\n",
    "the current value of the time-series. In Granger 'causality' analysis, we test\n",
    "whether the addition of a prediction of the time-series from another\n",
    "time-series through a multivariate auto-regressive model may improve our\n",
    "prediction of the present behavior of the time-series (reducing the value of\n",
    "the error term $\\epsilon_t$):\n",
    "\n",
    ".. math::\n",
    "\n",
    "   x_t = \\sum_{i=1}^{n}(a_i x_{t-i} + b_i y_{t-i}) + \\epsilon_t\n",
    "\n",
    "\n",
    "In our implementation of the algorithms used for this analysis, we follow\n",
    "closely the description put forth by Ding et al. ([Ding2006]_). Also, see\n",
    ":ref:`mar` and :ref:`ar` for examples even more closely modeled on the\n",
    "examples mentioned in their paper.\n",
    "\n",
    "Here, we will demonstrate the use of Granger 'causality' analysis with fMRI\n",
    "data. The data is provided as part of the distribution and is taken from a\n",
    "'resting state' scan. The data was motion corrected and averaged from several\n",
    "ROIs.\n",
    "\n",
    "We start by importing the needed modules:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nitime\n",
    "import nitime.analysis as nta\n",
    "import nitime.timeseries as ts\n",
    "import nitime.utils as tsu\n",
    "from nitime.viz import drawmatrix_channels\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\"\"\"\n",
    "We then define a few parameters of the data: the TR and the bounds on the\n",
    "frequency band of interest.\n",
    "\"\"\"\n",
    "\n",
    "TR = 2.00\n",
    "f_ub = 0.15\n",
    "f_lb = 0.02\n",
    "\n",
    "path = './timeseries_CSVs'\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if 'ROI_Subject' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "X = np.array([np.zeros(435)]) #quite possibly unnecessarily complicated, unsure how to do this\n",
    "for fnum in range(len(files)):\n",
    "    if int(files[fnum][29:32]) in bids_subset_ids.conn_ID.values:\n",
    "#         print(files[fnum][29:32])\n",
    "        data_rec = np.genfromtxt(files[fnum], dtype=float, delimiter=',', names=True)\n",
    "\n",
    "        roi_names = np.array(data_rec.dtype.names)\n",
    "        nseq = len(roi_names)\n",
    "        n_samples = data_rec.shape[0]\n",
    "        data = np.zeros((nseq, n_samples))\n",
    "\n",
    "        for n_idx, roi in enumerate(roi_names):\n",
    "            data[n_idx] = data_rec[roi]\n",
    "    #     display(data.shape)\n",
    "    #     if np.isnan(data).any() or np.isinf(data).any():\n",
    "    #         display(fnum)\n",
    "        \"\"\"\n",
    "        We normalize the data in each of the ROIs to be in units of % change and\n",
    "        initialize the TimeSeries object:\n",
    "        \"\"\"\n",
    "        pdata = tsu.percent_change(data)\n",
    "        time_series = ts.TimeSeries(pdata, sampling_interval=TR)\n",
    "        \"\"\"\n",
    "        We initialize the GrangerAnalyzer object, while specifying the order of the\n",
    "        autoregressive model to be 1 (predict the current behavior of the time-series\n",
    "        based on one time-point back).\n",
    "        \"\"\"\n",
    "        G = nta.GrangerAnalyzer(time_series, order=1)\n",
    "        \"\"\"\n",
    "        We are only interested in the physiologically relevant frequency band\n",
    "        (approximately 0.02 to 0.15 Hz).\n",
    "\n",
    "        The spectral resolution is different in these two different analyzers. In the\n",
    "        CoherenceAnalyzer, the spectral resolution depends on the size of the window\n",
    "        used for calculating the spectral density and cross-spectrum, whereas in the\n",
    "        GrangerAnalyzer it is derived, as determined by the user, from the MAR model\n",
    "        used.\n",
    "\n",
    "        For this reason, the indices used to access the relevant part of the spectrum\n",
    "        will be different in the different analyzers.\n",
    "        \"\"\"\n",
    "        freq_idx_G = np.where((G.frequencies > f_lb) * (G.frequencies < f_ub))[0]\n",
    "        try:\n",
    "            y_minus_x = np.mean(G.causality_xy[:, :, freq_idx_G] - G.causality_yx[:, :, freq_idx_G], -1)\n",
    "            y_minus_x = y_minus_x[np.logical_not(np.isnan(y_minus_x))]\n",
    "\n",
    "            temp = np.array([y_minus_x.tolist()])\n",
    "            X = np.concatenate((X, temp), axis=0)\n",
    "        except:\n",
    "            print(\"an error occured that prevented causality calculation for\", files[fnum])\n",
    "    #     display(files[fnum])\n",
    "X = X[1:]\n",
    "display(X.shape)\n",
    "# need to put all causality values in a single array and save it to npy file\n",
    "# probably need to make an empty array of the correct size first, as in read_matrices.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(g2)):\n",
    "        for j in range(len(g2[i])):\n",
    "            if np.isnan(g2[i][j]):\n",
    "                if i == j:\n",
    "                    g2[i][j] = 1.0\n",
    "                else:\n",
    "                    g2[i][j] = g2[j][i]\n",
    "# fig04 = drawmatrix_channels(g2, roi_names, size=[10., 10.], color_anchor=0)\n",
    "\n",
    "\"\"\"\n",
    "If these values are found to be significantly different than 0, this\n",
    "constitutes evidence for a correlation with a time-lag between the\n",
    "regions. This is a necessary (though not necessarily sufficient...) condition\n",
    "for establishing functional connectivity between the regions.\n",
    "\n",
    "Finally, we call plt.show(), to show the plots created:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
